{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.n_epoch = 50\n",
    "        self.batch_size = 5\n",
    "        self.z_dim = 64\n",
    "        self.n_dim = 64\n",
    "        self.y_dim = 10\n",
    "        self.D_lr = 0.01\n",
    "        self.G_lr = 0.002 # 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.img_size = 32\n",
    "        self.model_save_freq = 1000\n",
    "        self.img_save_freq = 100\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './ACGAN/Model/'\n",
    "        self.img_path = './ACGAN/Image/' \n",
    "        self.conv_dim = 64\n",
    "        self.d_dim = 64\n",
    "        self.D_out_dim = 16\n",
    "        self.train_img_path = \"./data/celeba/\"\n",
    "        self.num_res = 5\n",
    "        self.D_mode = ''\n",
    "        self.G_mode = ''\n",
    "        self.L_mode = ''\n",
    "        self.n_ch = 1\n",
    "        self.k = 0\n",
    "        self.lam = 0.001\n",
    "        self.gamma = 0.5\n",
    "        \n",
    "args = Parser()\n",
    "\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.img_path):\n",
    "    os.makedirs(args.img_path)\n",
    "\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.Resize((args.img_size,args.img_size)),\n",
    "                       T.ToTensor(),T.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class To_Image(nn.Module):\n",
    "    def __init__(self,img_size):\n",
    "        super(To_Image, self).__init__()\n",
    "        self.img_size = img_size\n",
    "    def forward(self,x):\n",
    "        return x.view(args.batch_size,-1, self.img_size, self.img_size)\n",
    "    \n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_dim, out_dim,3,1,1),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(args.z_dim + args.y_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Linear(1024, 2*args.n_dim*(args.img_size//4)*(args.img_size//4)),\n",
    "            To_Image((args.img_size//4)),\n",
    "            UpsampleBlock(2*args.n_dim, args.n_dim),\n",
    "            nn.BatchNorm2d(args.n_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            UpsampleBlock(args.n_dim, args.n_ch),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "    def forward(self,y):\n",
    "        one_hot_y = torch.zeros(args.batch_size, args.y_dim).to(device)\n",
    "        one_hot_y.scatter_(1,y.unsqueeze(1),1)\n",
    "        z = torch.randn(args.batch_size, args.z_dim).to(device)\n",
    "        return self.model(torch.cat([z,one_hot_y],1))\n",
    "    \n",
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self,in_dim, out_dim):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            DownSampleBlock(args.n_ch, args.n_dim),\n",
    "            DownSampleBlock(args.n_dim, args.n_dim*2),\n",
    "            DownSampleBlock(args.n_dim*2, args.n_dim*4),\n",
    "            nn.Conv2d(args.n_dim*4,args.n_dim*8,4,1,0)\n",
    "        )\n",
    "        \n",
    "        self.C_ = nn.Linear(512,1)\n",
    "        self.Q_ = nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        \n",
    "        shared_tensor = self.model(x).view(args.batch_size,-1)\n",
    "        C = F.sigmoid(self.C_(shared_tensor))\n",
    "        Q = self.Q_(shared_tensor)\n",
    "        \n",
    "        return C,Q\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class ACGAN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ACGAN, self).__init__()\n",
    "        \n",
    "        self.D = Discriminator()\n",
    "        self.G = Generator()\n",
    "        \n",
    "        self.G_optim = optim.Adam(self.G.parameters(), lr = args.G_lr , betas= (args.b1 ,args.b2))\n",
    "        self.D_optim = optim.Adam(self.D.parameters(), lr = args.D_lr , betas= (args.b1 ,args.b2))\n",
    "        \n",
    "        self.BCE = nn.BCELoss()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_hist = {}\n",
    "\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['D_loss'] = []\n",
    "        \n",
    "        self.apply(self.weight_init)\n",
    "        self.progress_photo = []\n",
    "        \n",
    "        self.real_label = torch.ones(args.batch_size,1).to(device)\n",
    "        self.fake_label = torch.zeros(args.batch_size,1).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self,img,y):\n",
    "        \n",
    "        img = img.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        ######### Train D #########\n",
    "        \n",
    "        self.D_optim.zero_grad()\n",
    "        \n",
    "        D_real, C_real = self.D(img)\n",
    "        D_real_loss = self.BCE(D_real, self.real_label)\n",
    "        C_real_loss = self.CE(C_real, y)\n",
    "        \n",
    "        self.G_img = self.G(y).detach()\n",
    "        D_fake, C_fake = self.D(self.G_img)\n",
    "        D_fake_loss = self.BCE(D_fake, self.fake_label)\n",
    "        C_fake_loss = self.CE(C_fake, y)\n",
    "        \n",
    "        self.D_loss = D_real_loss + C_real_loss + D_fake_loss + C_fake_loss\n",
    "        self.train_hist['D_loss'].append(self.D_loss.item())\n",
    "        self.D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "        ######### Train G #########\n",
    "        \n",
    "        self.G_optim.zero_grad()\n",
    "        \n",
    "        self.G_img = self.G(y)\n",
    "        D_fake, C_fake = self.D(self.G_img)\n",
    "        \n",
    "        D_fake_loss = self.BCE(D_fake, self.real_label)\n",
    "        C_fake_loss = self.CE(C_fake, y)\n",
    "        \n",
    "        self.G_loss = D_fake_loss + C_fake_loss\n",
    "        self.train_hist['G_loss'].append(self.G_loss.item())\n",
    "        self.G_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "        ######### Adjust lr ######### \n",
    "        \n",
    "        self.G_scheduler.step()\n",
    "        self.D_scheduler.step()\n",
    "        \n",
    "        \n",
    "        self.progress_photo.append(self.G_img[0].detach())\n",
    "        self.progress_photo = self.progress_photo[-args.img_save_freq:]\n",
    "        \n",
    "        \n",
    "    def weight_init(self,m):\n",
    "        if type(m) in [nn.Conv2d, nn.ConvTranspose2d, nn.Linear]:\n",
    "            #nn.init.xavier_normal_(m.weight,nn.init.calculate_gain('leaky_relu',param=0.02))\n",
    "            nn.init.kaiming_normal_(m.weight,0.2,nonlinearity='leaky_relu')\n",
    "            \n",
    "    def image_save(self, step):\n",
    "        \n",
    "        img_save_path = args.img_path + \"ACGAN_Step_\"+str(step)+\".png\"\n",
    "        save_image( torch.stack(self.progress_photo[:args.img_save_freq]), img_save_path , nrow=10, normalize=True, range=(-1,1))\n",
    "        print('Image saved')  \n",
    "        \n",
    "    def model_save(self,step):\n",
    "        path = args.model_path + 'ACGAN_Step_' + str(step) + '.pth'\n",
    "        torch.save({'ACGAN':self.state_dict()}, path)\n",
    "        print('Model saved')\n",
    "        \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + 'ACGAN_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location=lambda storage, loc: storage)['ACGAN'])\n",
    " \n",
    "    def plot_all_loss(self,step):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize= (20,8))\n",
    "        for k in self.train_hist.keys():\n",
    "            plt.plot(self.train_hist[k], label= k)\n",
    "        plt.ylabel('Loss',fontsize=15)\n",
    "        plt.xlabel('Number of Steps',fontsize=15)\n",
    "        plt.title('Loss',fontsize=30,fontweight =\"bold\")\n",
    "        plt.legend(loc = 'upper left')\n",
    "        fig.savefig(\"ACGAN_Loss_\"+str(step)+\".png\")\n",
    "        \n",
    "    def num_all_params(self,):\n",
    "        return sum([param.nelement() for param in self.parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader= DataLoader(datasets.MNIST('./data/mnist',\n",
    "                                        train=True, download=True,\n",
    "                                        transform=load_norm),\n",
    "                         batch_size= args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = ACGAN().to(device)\n",
    "epoch = 0\n",
    "all_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_scheduler = optim.lr_scheduler.StepLR(gan.G_optim,10000,0.5)\n",
    "D_scheduler = optim.lr_scheduler.StepLR(gan.D_optim,10000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step [1] | lr [0.002000] | D Loss: [6.9294] | G Loss: [49.2353] | Time: 0.6s\n",
      "| Step [2] | lr [0.002000] | D Loss: [166.3793] | G Loss: [74.9197] | Time: 0.3s\n",
      "| Step [3] | lr [0.002000] | D Loss: [91.3975] | G Loss: [78.4208] | Time: 0.4s\n",
      "| Step [4] | lr [0.002000] | D Loss: [136.8543] | G Loss: [57.6949] | Time: 0.4s\n",
      "| Step [5] | lr [0.002000] | D Loss: [98.7267] | G Loss: [93.1205] | Time: 0.3s\n",
      "| Step [6] | lr [0.002000] | D Loss: [116.3149] | G Loss: [42.0056] | Time: 0.4s\n",
      "| Step [7] | lr [0.002000] | D Loss: [101.4831] | G Loss: [65.8817] | Time: 0.4s\n",
      "| Step [8] | lr [0.002000] | D Loss: [54.7411] | G Loss: [56.8676] | Time: 0.3s\n",
      "| Step [9] | lr [0.002000] | D Loss: [195.0187] | G Loss: [42.7245] | Time: 0.3s\n",
      "| Step [10] | lr [0.002000] | D Loss: [87.7361] | G Loss: [53.9311] | Time: 0.4s\n",
      "| Step [11] | lr [0.002000] | D Loss: [111.3234] | G Loss: [52.9931] | Time: 0.4s\n",
      "| Step [12] | lr [0.002000] | D Loss: [101.7921] | G Loss: [106.1222] | Time: 0.4s\n",
      "| Step [13] | lr [0.002000] | D Loss: [85.2378] | G Loss: [58.4661] | Time: 0.4s\n",
      "| Step [14] | lr [0.002000] | D Loss: [79.4108] | G Loss: [82.2727] | Time: 0.3s\n",
      "| Step [15] | lr [0.002000] | D Loss: [111.4725] | G Loss: [77.6301] | Time: 0.3s\n",
      "| Step [16] | lr [0.002000] | D Loss: [31.3010] | G Loss: [22.5217] | Time: 0.3s\n",
      "| Step [17] | lr [0.002000] | D Loss: [76.6161] | G Loss: [15.7101] | Time: 0.3s\n",
      "| Step [18] | lr [0.002000] | D Loss: [68.2023] | G Loss: [28.7557] | Time: 0.3s\n",
      "| Step [19] | lr [0.002000] | D Loss: [132.8064] | G Loss: [31.1774] | Time: 0.3s\n",
      "| Step [20] | lr [0.002000] | D Loss: [57.7936] | G Loss: [4.8278] | Time: 0.3s\n",
      "| Step [21] | lr [0.002000] | D Loss: [44.4329] | G Loss: [42.6173] | Time: 0.3s\n",
      "| Step [22] | lr [0.002000] | D Loss: [53.3769] | G Loss: [50.7177] | Time: 0.3s\n",
      "| Step [23] | lr [0.002000] | D Loss: [62.2881] | G Loss: [62.5882] | Time: 0.3s\n",
      "| Step [24] | lr [0.002000] | D Loss: [45.9096] | G Loss: [51.0321] | Time: 0.3s\n"
     ]
    }
   ],
   "source": [
    "while epoch < args.n_epoch:\n",
    "    for i, (img, y) in enumerate(training_loader):    \n",
    "        \n",
    "        start_t = time.time()\n",
    "        gan(img,y)\n",
    "        end_t = time.time()\n",
    "        \n",
    "#         G_scheduler.step()\n",
    "#         D_scheduler.step()\n",
    "        \n",
    "        print('| Step [%d] | lr [%.6f] | D Loss: [%.4f] | G Loss: [%.4f] | Time: %.1fs' %\\\n",
    "              ( all_steps, gan.G_optim.param_groups[0]['lr'], gan.D_loss.item(), gan.G_loss.item(),\n",
    "               end_t - start_t))\n",
    "\n",
    "\n",
    "        if all_steps % args.show_freq == 0: #args.show_freq\n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1,3,1)\n",
    "            plt.imshow(to_img(gan.G_img[0].cpu()*0.5+0.5))\n",
    "            plt.show()\n",
    "            if all_steps % args.img_save_freq ==0: # args.img_save_freq\n",
    "                gan.image_save(all_steps)\n",
    "                gan.plot_all_loss('Training')\n",
    "                if all_steps % args.model_save_freq == 0: #args.model_save_freq\n",
    "                    gan.model_save(all_steps)\n",
    "        all_steps += 1\n",
    "        if all_steps > 5000:\n",
    "            raise StopIteration\n",
    "    epoch +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.G_optim.param_groups[0]['lr'] *= 0.5 \n",
    "gan.D_optim.param_groups[0]['lr'] *= 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
